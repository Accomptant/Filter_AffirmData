{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oON4sRh3IGHK",
        "outputId": "57d0d8ec-3228-4776-ba5b-9abc4e15199b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import calendar\n",
        "import datetime\n",
        "import re\n",
        "import os\n",
        "\n",
        "def filter_data(input_file_path,keyword):\n",
        "    file = os.listdir(input_file_path)[0]\n",
        "    dataFrame= pd.read_csv(os.path.join(input_file_path, file))\n",
        "    # select rows containing text \"Affirm\"\n",
        "    data_filtered = dataFrame.loc[dataFrame['DESCRIPTION'].str.contains(keyword),['DATE', 'DESCRIPTION', 'RECEIVED']]\n",
        "    # data_filtered.to_csv(os.path.join(output_file_path, file), index = False)\n",
        "\n",
        "    #split the decription\n",
        "    new =data_filtered.DESCRIPTION.str.split(expand=True)\n",
        "    data_filtered['DEPOSIT_ID']=new[15]\n",
        "    data_filtered.drop(columns =[\"DESCRIPTION\"], inplace = True)\n",
        "    data_filtered['DESCRIPTION']=new[3]+' '+new[4]\n",
        "\n",
        "    # split the deposit id\n",
        "    new_id=data_filtered.DEPOSIT_ID.str.split(\":\",expand=True)\n",
        "    data_filtered.drop(columns =[\"DEPOSIT_ID\"], inplace = True)\n",
        "    data_filtered['DEPOSIT_ID']=new_id[1]\n",
        "    return data_filtered"
      ],
      "metadata": {
        "id": "cri-14jKdYJe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_filtered(res_data,affirm_report):\n",
        "   #read the affirm report file\n",
        "   data_report=pd.read_csv(affirm_report)\n",
        "   data_report.rename(columns = {'deposit_id':'DEPOSIT_ID'}, inplace = True)\n",
        "   #combine two csv files based on DEPOSIT ID\n",
        "   df = pd.merge(res_data, data_report,on=\"DEPOSIT_ID\")\n",
        "  #  print(df.to_string())\n",
        "   df.rename(columns = {'RECEIVED':'BANK AMOUNT'}, inplace = True)\n",
        "   df.rename(columns = {'order_id':'ORDER'}, inplace = True)\n",
        "   df['FEE']=df['fees']+df['txn_fees']\n",
        "   df['ORDER']=df['ORDER'].astype(str)\n",
        "   return df\n"
      ],
      "metadata": {
        "id": "xIBK62sh66Os"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_order(data_report,order_report_table):\n",
        "    report_table=pd.read_csv(order_report_table)   #read the order report table\n",
        "    report_table.rename(columns = {'Order_Number':'ORDER'}, inplace = True)\n",
        "    #covert the object type to float\n",
        "    report_table['Item_Price']=report_table['Item_Price'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    report_table['Item_Discount']=report_table['Item_Discount'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    \n",
        "    #combine report table to df\n",
        "    data_table=pd.merge(data_report,report_table,on='ORDER')\n",
        "    data_table.rename(columns = {'Item_Price':'PRICE'}, inplace = True) # rename columns\n",
        "    data_table.rename(columns = {'Item_Discount':'DISCOUNT'}, inplace = True) # rename columns\n",
        "    data_table.rename(columns = {'Order_Date':'QBO DATE'}, inplace = True) # rename columns\n",
        "    data_table['QBO Description']=data_table['ORDER']\n",
        "    data_table['INCOME']=data_table['PRICE']\n",
        "\n",
        "    #add new columns\n",
        "    data_table['PRICE']=data_table['PRICE'].astype(float)\n",
        "    data_table['DISCOUNT']=data_table['DISCOUNT'].astype(float)\n",
        "    data_table['NET AMOUNT']=data_table['PRICE']+data_table['FEE']+data_table['DISCOUNT']\n",
        "    \n",
        "    #add a new columns check by comparing two columns\n",
        "    data_table['CHECK']=np.where((data_table['NET AMOUNT'] == data_table['total_settled']), 'Correct', 'Incorrect')\n",
        "    # print(data_table.to_string())\n",
        "\n",
        "    #change the datatype to int\n",
        "    data_table['ORDER']=data_table['ORDER'].astype(int)\n",
        "\n",
        "    return data_table"
      ],
      "metadata": {
        "id": "AxZzRqRE9dAK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=filter_data('/content/drive/MyDrive/Colab Notebooks/input_file_path','AFFIRM')\n",
        "res_data=merge_filtered(data,'/content/drive/MyDrive/Affirm Testing/Affirm_Report_0123.csv')\n",
        "merge_order=merge_order(res_data,'/content/drive/MyDrive/Affirm Testing/order_report_Jan22_Jan23.csv')\n",
        "print(merge_order)"
      ],
      "metadata": {
        "id": "O5eU-gpt6Zfv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}