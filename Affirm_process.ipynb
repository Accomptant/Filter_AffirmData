{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oON4sRh3IGHK",
        "outputId": "47f4eecf-e90c-4d1c-93e7-4a4aa4ffcd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import calendar\n",
        "import datetime\n",
        "import re\n",
        "import os\n",
        "\n",
        "def filter_data(input_file_path,keyword):\n",
        "    file = os.listdir(input_file_path)[0]\n",
        "    dataFrame= pd.read_csv(os.path.join(input_file_path, file))\n",
        "    # select rows containing text \"Affirm\"\n",
        "    data_filtered = dataFrame.loc[dataFrame['DESCRIPTION'].str.contains(keyword),['DATE', 'DESCRIPTION', 'RECEIVED']]\n",
        "    \n",
        "    #split the decription\n",
        "    new =data_filtered.DESCRIPTION.str.split(expand=True)\n",
        "    data_filtered['DEPOSIT']=new[15]\n",
        "    data_filtered.drop(columns =[\"DESCRIPTION\"], inplace = True)\n",
        "    data_filtered['DESCRIPTION']=new[3]+' '+new[4]\n",
        "   \n",
        "    # split the deposit id\n",
        "    data_filtered[['IID','DEPOSIT_ID']]=data_filtered.DEPOSIT.str.split(\":\",expand=True)\n",
        "    data_filtered.drop(columns =[\"DEPOSIT\"], inplace = True)\n",
        "    data_filtered.drop(columns =[\"IID\"], inplace = True)\n",
        "\n",
        "    # print(data_filtered.to_string())\n",
        "    return data_filtered"
      ],
      "metadata": {
        "id": "cri-14jKdYJe"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_filtered(res_data,affirm_report):\n",
        "   #read the affirm report file\n",
        "   data_report=pd.read_csv(affirm_report)\n",
        "   data_report.rename(columns = {'deposit_id':'DEPOSIT_ID'}, inplace = True)\n",
        "   #drop duplicate based on order id\n",
        "   new_dt=data_report.drop_duplicates(subset='order_id')\n",
        "   #print(new_dt)\n",
        "   #combine two csv files based on DEPOSIT ID\n",
        "   df = pd.merge(res_data,new_dt,on=\"DEPOSIT_ID\")\n",
        "  \n",
        "   df.rename(columns = {'RECEIVED':'BANK AMOUNT'}, inplace = True)\n",
        "   df.rename(columns = {'order_id':'ORDER'}, inplace = True)\n",
        "   df['FEE']=df['fees']+df['txn_fees']\n",
        "   df['ORDER']=df['ORDER'].astype(str)\n",
        "  # print(df.to_string())\n",
        "   return df\n"
      ],
      "metadata": {
        "id": "xIBK62sh66Os"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_order(data_report,order_report_table):\n",
        "    report_table=pd.read_csv(order_report_table)   #read the order report table\n",
        "    report_table.rename(columns = {'Order_Number':'ORDER'}, inplace = True)\n",
        "    #convert the object type to float\n",
        "    report_table['Item_Price']=report_table['Item_Price'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    report_table['Item_Discount']=report_table['Item_Discount'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    # print(report_table)\n",
        "    #combine report table to df\n",
        "    data_table=pd.merge(data_report,report_table,on='ORDER')\n",
        "    data_table.rename(columns = {'Item_Price':'PRICE'}, inplace = True) # rename columns\n",
        "    data_table.rename(columns = {'Item_Discount':'DISCOUNT'}, inplace = True) # rename columns\n",
        "    data_table.rename(columns = {'Order_Date':'QBO DATE'}, inplace = True) # rename columns\n",
        "    data_table['QBO Description']=data_table['ORDER']\n",
        "    data_table['INCOME']=data_table['PRICE']\n",
        "\n",
        "    #add new columns\n",
        "    data_table['PRICE']=data_table['PRICE'].astype(float)\n",
        "    data_table['DISCOUNT']=data_table['DISCOUNT'].astype(float)\n",
        "    data_table['NET AMOUNT']=data_table['PRICE']+data_table['FEE']+data_table['DISCOUNT']\n",
        "    \n",
        "    #add a new columns check by comparing two columns\n",
        "    data_table['CHECK']=np.where((data_table['NET AMOUNT'] == data_table['total_settled']), 'Correct', 'Incorrect')\n",
        "    # print(data_table.to_string())\n",
        "    \n",
        "    #change the datatype to int\n",
        "    data_table['ORDER']=data_table['ORDER'].astype(int)\n",
        "\n",
        "    return data_table"
      ],
      "metadata": {
        "id": "AxZzRqRE9dAK"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_register(order_data,reg_report,output_file_path):\n",
        "    current_date=datetime.datetime.now()\n",
        "    registr_report=pd.read_csv(reg_report)\n",
        "    order_data['Success'] = order_data['ORDER'].isin(registr_report['Order id']).astype(int)\n",
        "    registr_report.rename(columns = {'Order id':'ORDER'}, inplace = True) # rename columns\n",
        "    registr_report.rename(columns = {'Session Name':'SESSION'}, inplace = True) # rename columns\n",
        "\n",
        "    #split the session Name to get the course month\n",
        "    registr_report[['cl1','cl2','Month']]=registr_report.SESSION.str.split(\"|\",expand=True)\n",
        "    registr_report[['colmn0','colmn1','colmn2','Course Month','clmn4']]=registr_report.Month.str.split(expand=True)\n",
        "    \n",
        "    registr_report['Course Month']= pd.to_datetime(registr_report['Course Month'])\n",
        "    registr_report['Account'] = 'N/A'\n",
        "    registr_report.loc[registr_report['Course Month'] < current_date, 'Account'] = '4000 Tution Income'\n",
        "    registr_report.loc[registr_report['Course Month'] > current_date, 'Account'] = '2200 Unearned Revenue'\n",
        "\n",
        "    registr_report['Course Month']=registr_report['Course Month'].dt.strftime('%b %Y') \n",
        "    \n",
        "   \n",
        "    #trying to merge the files\n",
        "    new_df=pd.merge(order_data,registr_report,on='ORDER',how='left')\n",
        "    new_df['Course Month']=new_df['Course Month'].astype(object)\n",
        "    new_df['Course Month']=np.where((new_df['Success'] == 1), new_df['Course Month'], 'N/A')\n",
        "    new_df.loc[new_df['Course Month'] == 'N/A', 'Account'] = '4000 Tution Income'\n",
        "   \n",
        "    #create ne df from new_df with required colmn\n",
        "    output_data=new_df[['DATE', 'DESCRIPTION','BANK AMOUNT','PRICE','FEE','DISCOUNT','NET AMOUNT','CHECK','Course Month','ORDER','QBO DATE','QBO Description','INCOME','Account']].copy()\n",
        "    # print(output_data.dtypes)\n",
        "    # print(output_data.to_string())\n",
        "    #convert the output to csv file\n",
        "    output_data.to_csv('affirm_report_summary2.csv', encoding = 'utf-8-sig') \n",
        "    report='affirm_report_summary2.csv'\n",
        "    output_data.to_csv(os.path.join(output_file_path,report), index = False) "
      ],
      "metadata": {
        "id": "P2V-LqRtZsqJ"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=filter_data('/content/drive/MyDrive/Colab Notebooks/input_file_path','AFFIRM')\n",
        "res_data=merge_filtered(data,'/content/drive/MyDrive/Affirm Testing/Affirm_Report_0123.csv')\n",
        "merge_data=merge_order(res_data,'/content/drive/MyDrive/Affirm Testing/order_report_Jan22_Jan23.csv')\n",
        "output=check_register(merge_data,'/content/drive/MyDrive/Colab Notebooks/registration_report_Dec22 _Jan23  - Sheet1.csv','/content/drive/MyDrive/Colab Notebooks/output_file_path')\n",
        "# print(output)"
      ],
      "metadata": {
        "id": "O5eU-gpt6Zfv"
      },
      "execution_count": 261,
      "outputs": []
    }
  ]
}