{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ROEo_CpWnn1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3219d20-1bfc-4b6e-81ab-28457f0cb38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import calendar\n",
        "import datetime\n",
        "import re\n",
        "import os\n",
        "\n",
        "def filter_data(input_file_path, output_file_path,keyword,affirm_report,order_report_table,reg_report):\n",
        "    \n",
        "    for file in os.listdir(input_file_path):\n",
        "        dataFrame= pd.read_csv(os.path.join(input_file_path, file))\n",
        "        # select rows containing text \"Affirm\"\n",
        "        data_filtered = dataFrame.loc[dataFrame['DESCRIPTION'].str.contains(keyword),['DATE', 'DESCRIPTION', 'RECEIVED']]\n",
        "        # data_filtered.to_csv(os.path.join(output_file_path, file), index = False)\n",
        "\n",
        "        #split the decription\n",
        "        new =data_filtered.DESCRIPTION.str.split(expand=True)\n",
        "        data_filtered['DEPOSIT_ID']=new[15]\n",
        "        data_filtered.drop(columns =[\"DESCRIPTION\"], inplace = True)\n",
        "        data_filtered['DESCRIPTION']=new[3]+' '+new[4]\n",
        "\n",
        "        # split the deposit id\n",
        "        new_id=data_filtered.DEPOSIT_ID.str.split(\":\",expand=True)\n",
        "        data_filtered.drop(columns =[\"DEPOSIT_ID\"], inplace = True)\n",
        "        data_filtered['DEPOSIT_ID']=new_id[1]\n",
        "      \n",
        "        #read the affirm report file\n",
        "        data_report=pd.read_csv(affirm_report)\n",
        "        data_report.rename(columns = {'deposit_id':'DEPOSIT_ID'}, inplace = True)\n",
        "  \n",
        "        #combine two csv files based on DEPOSIT ID\n",
        "        df = pd.merge(data_filtered, data_report,on=\"DEPOSIT_ID\")\n",
        "        # print(df.to_string())\n",
        "        df.rename(columns = {'RECEIVED':'BANK AMOUNT'}, inplace = True)\n",
        "        df.rename(columns = {'order_id':'ORDER'}, inplace = True)\n",
        "        df['FEE']=df['fees']+df['txn_fees']\n",
        "        df['ORDER']=df['ORDER'].astype(str)\n",
        "\n",
        "        #read the order report table\n",
        "        report_table=pd.read_csv(order_report_table)\n",
        "        report_table.rename(columns = {'Order_Number':'ORDER'}, inplace = True)\n",
        "        #covert the object type to float\n",
        "        report_table['Item_Price']=report_table['Item_Price'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "        report_table['Item_Discount']=report_table['Item_Discount'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "       \n",
        "        #combine report table to df\n",
        "        data_table=pd.merge(df,report_table,on='ORDER')\n",
        "        data_table.rename(columns = {'Item_Price':'PRICE'}, inplace = True) # rename columns\n",
        "        data_table.rename(columns = {'Item_Discount':'DISCOUNT'}, inplace = True) # rename columns\n",
        "        data_table.rename(columns = {'Order_Date':'QBO DATE'}, inplace = True) # rename columns\n",
        "        data_table['QBO Description']=data_table['ORDER']\n",
        "        data_table['INCOME']=data_table['PRICE']\n",
        "\n",
        "        #add new columns\n",
        "        data_table['PRICE']=data_table['PRICE'].astype(float)\n",
        "        data_table['DISCOUNT']=data_table['DISCOUNT'].astype(float)\n",
        "        data_table['NET AMOUNT']=data_table['PRICE']+data_table['FEE']+data_table['DISCOUNT']\n",
        "        \n",
        "        #add a new columns check by comparing two columns\n",
        "        data_table['CHECK']=np.where((data_table['NET AMOUNT'] == data_table['total_settled']), 'Correct', 'Incorrect')\n",
        "        # print(data_table.to_string())\n",
        "\n",
        "        #change the datatype to int\n",
        "        data_table['ORDER']=data_table['ORDER'].astype(int)\n",
        "\n",
        "        #compare the result with registration report to get coursemonth\n",
        "        registr_report=pd.read_csv(reg_report)\n",
        "        data_table['Success'] = data_table['ORDER'].isin(registr_report['Order id']).astype(int)\n",
        "       \n",
        "       \n",
        "        registr_report.rename(columns = {'Order id':'ORDER'}, inplace = True) # rename columns\n",
        "        registr_report.rename(columns = {'Session Name':'SESSION'}, inplace = True) # rename columns\n",
        "\n",
        "        #split the session Name to get the course month\n",
        "        new_data=registr_report.SESSION.str.split(\"|\",expand=True)\n",
        "        registr_report['Month']=new_data[2]\n",
        "        data_date=registr_report.Month.str.split(expand=True)\n",
        "        registr_report['CourseEndMonth']=data_date[3]\n",
        "        \n",
        "        #trying to merge the files\n",
        "        new_df=pd.merge(data_table,registr_report,on='ORDER',how='left')\n",
        "        new_df['Course Month']=np.where((new_df['Success'] == 1), new_df['CourseEndMonth'], 'N/A')\n",
        "        Account=[]\n",
        "        month=[]\n",
        "        for  index,row in new_df.iterrows():\n",
        "            # print((index))\n",
        "            if row[65]=='N/A':\n",
        "              Account.append('4000 Tution Income')\n",
        "              month.append('N/A')\n",
        "            else:\n",
        "              e_date=pd.to_datetime(row[65])\n",
        "              month_num=e_date.month\n",
        "              e_yr=e_date.year\n",
        "              month_nme=calendar.month_name[month_num]\n",
        "              new_mon= month_nme+ str(e_yr)\n",
        "              month.append(new_mon)\n",
        "              now = datetime.datetime.now()\n",
        "              if now<e_date:\n",
        "                Account.append('2200 Unearned Revenue')\n",
        "              else:\n",
        "                Account.append('4000 Tution Income')\n",
        "\n",
        "        new_df['Account']=Account\n",
        "        new_df['Month']= month\n",
        "        # print(new_df.to_string())\n",
        "        output_data=new_df[['DATE', 'DESCRIPTION','BANK AMOUNT','PRICE','FEE','DISCOUNT','NET AMOUNT','CHECK','Month','ORDER','QBO DATE','QBO Description','INCOME','Account']].copy()\n",
        "        output_data.rename(columns = {'Month':'Course Month'}, inplace = True) # rename columns\n",
        "\n",
        "        # print(output_data.to_string())\n",
        "        #convert the output to csv file\n",
        "        output_data.to_csv('affirm_report_summary.csv', encoding = 'utf-8-sig') \n",
        "        report='affirm_report_summary.csv'\n",
        "        output_data.to_csv(os.path.join(output_file_path,report), index = False) \n",
        "        \n",
        "    "
      ],
      "metadata": {
        "id": "TO6tpOpbv3EL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_data('/content/drive/MyDrive/Colab Notebooks/input_file_path','/content/drive/MyDrive/Colab Notebooks/output_file_path','AFFIRM','/content/drive/MyDrive/Affirm Testing/Affirm_Report_0123.csv','/content/drive/MyDrive/Affirm Testing/order_report_Jan22_Jan23.csv','/content/drive/MyDrive/Colab Notebooks/registration_report_Dec22 _Jan23  - Sheet1.csv')\n"
      ],
      "metadata": {
        "id": "alfh0h-y51K9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}