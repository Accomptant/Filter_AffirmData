{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ROEo_CpWnn1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d435206-52df-49f7-a0dd-50ed6e03b8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import calendar\n",
        "import datetime\n",
        "import re\n",
        "import os\n",
        "\n",
        "def filter_data(input_file_path, output_file_path,keyword,affirm_report,order_report_table,reg_report):\n",
        "    current_date=datetime.datetime.now()\n",
        "    file = os.listdir(input_file_path)[0]\n",
        "    dataFrame= pd.read_csv(os.path.join(input_file_path, file))\n",
        "    # select rows containing text \"Affirm\"\n",
        "    data_filtered = dataFrame.loc[dataFrame['DESCRIPTION'].str.contains(keyword),['DATE', 'DESCRIPTION', 'RECEIVED']]\n",
        "\n",
        "    #split the decription\n",
        "    new =data_filtered.DESCRIPTION.str.split(expand=True)\n",
        "    data_filtered['DEPOSIT']=new[15]\n",
        "    data_filtered.drop(columns =[\"DESCRIPTION\"], inplace = True)\n",
        "    data_filtered['DESCRIPTION']=new[3]+' '+new[4]\n",
        "  \n",
        "    # split the deposit id\n",
        "    data_filtered[['IID','DEPOSIT_ID']]=data_filtered.DEPOSIT.str.split(\":\",expand=True)\n",
        "    data_filtered.drop(columns =[\"DEPOSIT\"], inplace = True)\n",
        "    data_filtered.drop(columns =[\"IID\"], inplace = True)\n",
        "\n",
        "      \n",
        "    #read the affirm report file\n",
        "    data_report=pd.read_csv(affirm_report)\n",
        "    data_report.rename(columns = {'deposit_id':'DEPOSIT_ID'}, inplace = True) \n",
        "    new_data_report=data_report.drop_duplicates(subset='order_id') #drop duplicate based on order id\n",
        "    #combine two csv files based on DEPOSIT ID\n",
        "    df = pd.merge(data_filtered, new_data_report,on=\"DEPOSIT_ID\")\n",
        "    # print(df.to_string())\n",
        "    df.rename(columns = {'RECEIVED':'BANK AMOUNT'}, inplace = True)\n",
        "    df.rename(columns = {'order_id':'ORDER'}, inplace = True)\n",
        "    df['FEE']=df['fees']+df['txn_fees']\n",
        "    df['ORDER']=df['ORDER'].astype(str)\n",
        "\n",
        "    #read the order report table\n",
        "    report_table=pd.read_csv(order_report_table)\n",
        "    report_table.rename(columns = {'Order_Number':'ORDER'}, inplace = True)\n",
        "    #covert the object type to float\n",
        "    report_table['Item_Price']=report_table['Item_Price'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    report_table['Item_Discount']=report_table['Item_Discount'].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    \n",
        "    #combine report table to df\n",
        "    data_table=pd.merge(df,report_table,on='ORDER')\n",
        "    data_table.rename(columns = {'Item_Price':'PRICE'}, inplace = True) # rename columns\n",
        "    data_table.rename(columns = {'Item_Discount':'DISCOUNT'}, inplace = True) # rename columns\n",
        "    data_table.rename(columns = {'Order_Date':'QBO DATE'}, inplace = True) # rename columns\n",
        "    data_table['QBO Description']=data_table['ORDER']\n",
        "    data_table['INCOME']=data_table['PRICE']\n",
        "\n",
        "    #add new columns\n",
        "    data_table['PRICE']=data_table['PRICE'].astype(float)\n",
        "    data_table['DISCOUNT']=data_table['DISCOUNT'].astype(float)\n",
        "    data_table['NET AMOUNT']=data_table['PRICE']+data_table['FEE']+data_table['DISCOUNT']\n",
        "    \n",
        "    #add a new columns check by comparing two columns\n",
        "    data_table['CHECK']=np.where((data_table['NET AMOUNT'] == data_table['total_settled']), 'Correct', 'Incorrect')\n",
        "\n",
        "    #change the datatype to int\n",
        "    data_table['ORDER']=data_table['ORDER'].astype(int)\n",
        "\n",
        "    #compare the result with registration report to get coursemonth\n",
        "    registr_report=pd.read_csv(reg_report)\n",
        "    data_table['Success'] = data_table['ORDER'].isin(registr_report['Order id']).astype(int)\n",
        "    registr_report.rename(columns = {'Order id':'ORDER'}, inplace = True) # rename columns\n",
        "    registr_report.rename(columns = {'Session Name':'SESSION'}, inplace = True) # rename columns\n",
        "\n",
        "    #split the session Name to get the course month\n",
        "    registr_report[['cl1','cl2','Month']]=registr_report.SESSION.str.split(\"|\",expand=True)\n",
        "    registr_report[['colmn0','colmn1','colmn2','Course Month','clmn4']]=registr_report.Month.str.split(expand=True)\n",
        "    \n",
        "    registr_report['Course Month']= pd.to_datetime(registr_report['Course Month'])\n",
        "    registr_report['Account'] = 'N/A'\n",
        "    registr_report.loc[registr_report['Course Month'] < current_date, 'Account'] = '4000 Tution Income'\n",
        "    registr_report.loc[registr_report['Course Month'] > current_date, 'Account'] = '2200 Unearned Revenue'\n",
        "\n",
        "    registr_report['Course Month']=registr_report['Course Month'].dt.strftime('%b %Y') \n",
        "    \n",
        "    \n",
        "    #trying to merge the files\n",
        "    new_df=pd.merge(data_table,registr_report,on='ORDER',how='left')\n",
        "    new_df['Course Month']=new_df['Course Month'].astype(object)\n",
        "    new_df['Course Month']=np.where((new_df['Success'] == 1), new_df['Course Month'], 'N/A')\n",
        "    new_df.loc[new_df['Course Month'] == 'N/A', 'Account'] = '4000 Tution Income'\n",
        "    df2 =new_df.groupby(\"BANK AMOUNT\").size().reset_index(name='counts')\n",
        "    df_sum=new_df.groupby(\"BANK AMOUNT\").sum()\n",
        "    # df_sum['Bankamount']=df_sum['BANK AMOUNT']\n",
        "    # new_amount =df_sum.Bankamount.str.split('$',expand=True)\n",
        "    df_sum['DrN']=df_sum.FEE.abs()+df_sum['DISCOUNT']\n",
        "    new_dflist=pd.merge(new_df,df_sum,on='BANK AMOUNT',how='left')\n",
        "    # new_dflist['BANK AMOUNT']=new_dflist['BANK AMOUNT'].astype(str)\n",
        "    new_dflist2=new_dflist['BANK AMOUNT'].str.split('$',n = 1,expand=True)\n",
        "    new_dflist['Bankamount']=new_dflist2[1].apply(lambda x: float(x.split()[0].replace(',', '')))\n",
        "    new_df['Credit(Income/Revenue)']=new_dflist['DrN']+new_dflist['Bankamount']\n",
        "    # print(new_dflist.to_string())\n",
        "    #create ne df from new_df with required colmn\n",
        "    output_data=new_df[['DATE', 'DESCRIPTION','BANK AMOUNT','PRICE','FEE','DISCOUNT','NET AMOUNT','CHECK','Course Month','ORDER','QBO DATE','QBO Description','INCOME','Account','Credit(Income/Revenue)']].copy()\n",
        "    # print(output_data.dtypes)\n",
        "    print(output_data.to_string())\n",
        "    #convert the output to csv file\n",
        "    output_data.to_csv('affirm_report_nsummary.csv', encoding = 'utf-8-sig') \n",
        "    report='affirm_report_nsummary.csv'\n",
        "    # output_data.to_csv(os.path.join(output_file_path,report), index = False) \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "TO6tpOpbv3EL"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_data('/content/drive/MyDrive/Colab Notebooks/input_file_path','/content/drive/MyDrive/Colab Notebooks/output_file_path','AFFIRM','/content/drive/MyDrive/Affirm Testing/Affirm_Report_0123.csv','/content/drive/MyDrive/Affirm Testing/order_report_Jan22_Jan23.csv','/content/drive/MyDrive/Colab Notebooks/registration_report_Dec22 _Jan23  - Sheet1.csv')\n"
      ],
      "metadata": {
        "id": "alfh0h-y51K9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}